{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # try to use GPU, if not then CPU\n",
    "print(device)\n",
    "\n",
    "'''\n",
    "Hyperparameters\n",
    "'''\n",
    "block_size = 80 # also becomes context size\n",
    "batch_size = 16\n",
    "iterations = 1_000\n",
    "eval_iters = 100\n",
    "learning_rate = 3e-4\n",
    "embd_dim = 400\n",
    "num_decoders = 4\n",
    "num_heads = 4\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Vocabulary\n",
    "'''\n",
    "words = \"\"\n",
    "with open('crime_and_punishment.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "    txt = txt.lower()\n",
    "    words = list(set(txt.split()))\n",
    "    txt = list(txt.split()) # txt is a list of words\n",
    "\n",
    "vocab_size = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train/Test Split\n",
    "'''\n",
    "word_to_int = {s:i for i, s in enumerate(words)}\n",
    "int_to_word = {i:s for i, s in enumerate(words)}\n",
    "encode = lambda word_list: [word_to_int[s] for s in word_list]\n",
    "decode = lambda index_list: [int_to_word[i] for i in index_list]\n",
    "\n",
    "data = torch.tensor(encode(txt), dtype=torch.long)\n",
    "\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]\n",
    "\n",
    "\n",
    "def get_random_batch(portion):\n",
    "    data = train_data if portion == 'train' else test_data\n",
    "    block_indices = torch.randint(low=0, high=len(data) - block_size, size=(batch_size,))\n",
    "    \n",
    "    inputs = [data[i:i+block_size] for i in block_indices] # list of input blocks\n",
    "    inputs = torch.stack(inputs) # stack\n",
    "    targets = [data[i+1:i+block_size+1] for i in block_indices] # list of target blocks (offset from input blocks by 1)\n",
    "    targets = torch.stack(targets) # stack\n",
    "    \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "'''\n",
    "Create Model\n",
    "'''\n",
    "from GPT import *\n",
    "gpt = GPT(vocab_size, embd_dim, block_size, num_decoders, num_heads, dropout)\n",
    "gpt = gpt.to(device) # Use GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Estimate Losses During Training\n",
    "'''\n",
    "@torch.no_grad()\n",
    "def estimate_losses():\n",
    "    out = {} # dict\n",
    "    gpt.eval() # product outputs without training or even calculating gradients\n",
    "    for split in ['train', 'test']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            inputs, targets = get_random_batch(split)\n",
    "            logits, loss = gpt.forward(inputs, targets)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    return out\n",
    "\n",
    "\n",
    "'''\n",
    "Optimizer\n",
    "'''\n",
    "opt = torch.optim.AdamW(gpt.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "'''\n",
    "Training Loop\n",
    "'''\n",
    "for iter in range(iterations): # optimization loop\n",
    "    inputs, targets = get_random_batch('train')\n",
    "\n",
    "    logits, loss = gpt.forward(inputs, targets)\n",
    "    opt.zero_grad(set_to_none=True) # do not accumulate gradients over time\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_losses()\n",
    "        print(f\"iter: {iter}, train loss: {losses['train']}, test loss: {losses['test']}\")\n",
    "\n",
    "'''\n",
    "Save Learned Parameters\n",
    "'''\n",
    "torch.save(gpt.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.load_state_dict(torch.load('model_weights.pth'))\n",
    "prompt = ['good', 'afternoon']\n",
    "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "generated_words = decode(gpt.generate(context.unsqueeze(0), num_new_tokens=300)[0].tolist())\n",
    "\n",
    "newline = 14\n",
    "response = ''\n",
    "for i, word in enumerate(generated_words, 1):\n",
    "    response += word + ' '\n",
    "    if i % newline == 0:\n",
    "        response += '\\n'\n",
    "\n",
    "print('\\n' + response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
